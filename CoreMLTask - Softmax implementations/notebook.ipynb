{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code for saidl assignment CoreML task. \n",
        "\n",
        "https://github.com/vimarsh244/SAiDL-Summer-Assignment-2023/tree/main/CoreMLTask%20-%20Softmax%20implementations\n",
        "\n",
        "This notebook has been run on Google Colab, if running locally dependencies might need to be installed."
      ],
      "metadata": {
        "id": "6OlMm0-ElPIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries and downloading dataset\n"
      ],
      "metadata": {
        "id": "MG9S1fwbk3ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Importing dependencies\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "from torchvision.datasets import CIFAR100 #dataset\n",
        "\n",
        "\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Gumbel\n",
        "\n",
        "from torchsummary import summary\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "TuZK2Bfbk6HX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CIFAR100(root = 'data/', download = True, transform = ToTensor())\n",
        "test_dataset = CIFAR100(root = 'data/', train = False, transform = ToTensor())\n",
        "# using pytorch's data loader to download CIFAR100 dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNzPPnD0lCbq",
        "outputId": "edde99ae-ca41-44a0-cedd-7ca16508e106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:01<00:00, 98498873.92it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dataset))\n",
        "print(len(test_dataset))\n",
        "\n",
        "classes = dataset.classes \n",
        "print('# of classes:', len(classes))\n",
        "print('names.. \\n', classes)\n",
        "\n",
        "#shape of the image tensor\n",
        "img, label = dataset[31]\n",
        "img_shape = img.shape\n",
        "img_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kQcGAKOlG4d",
        "outputId": "381695a7-a84d-4271-dc58-5133419b1876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n",
            "10000\n",
            "Number of Classes: 100\n",
            "Class Names :\n",
            " ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"1 - Max & Min Pixel Values:\", \"Max:\", torch.max(img), \"Min:\", torch.min(img))\n",
        "# print(\"2 - Pixel Values for all Channels:\\n\", img[:, 20:25, 20:25])"
      ],
      "metadata": {
        "id": "-y7L7ZnrlM9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Dataset"
      ],
      "metadata": {
        "id": "aB93rwDslR-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2718) ##settling a manual seed to get similar results everytime"
      ],
      "metadata": {
        "id": "hLULhs0vmpY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "val_size = 10000\n",
        "train_size = len(dataset) - val_size\n",
        "\n",
        "train_ds, val_ds = random_split(dataset,[train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3L7WPilYlUrT",
        "outputId": "3e78ac19-a8a7-421b-d5a0-1bbf172b7ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40000, 10000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128"
      ],
      "metadata": {
        "id": "Awkhy5FMlfG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defininf Loaders for training process\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle = True, num_workers=4, pin_memory =True)\n",
        "val_loader = DataLoader(val_ds, batch_size, num_workers=4, pin_memory =True)\n",
        "test_loader = DataLoader(test_dataset, batch_size, num_workers=4, pin_memory =True)"
      ],
      "metadata": {
        "id": "b_RTR5g1lm4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Used example method to check if CPU / GPU is available and use that for training\n",
        "\n",
        "torch.cuda.is_available()\n",
        "\n",
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "\n",
        "device = get_default_device()\n",
        "device\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "\n",
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)"
      ],
      "metadata": {
        "id": "7ZeufDWHltRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "idk\n"
      ],
      "metadata": {
        "id": "ffs_I-_KmP0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR 100 accuracy, etc default functions (Pytorch Example)\n",
        "\n",
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
        "\n",
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
        "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_acc']))"
      ],
      "metadata": {
        "id": "zqopX4ULmR1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Using ResNet 12 structure to train the model"
      ],
      "metadata": {
        "id": "6wYk3CwbmfKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Different methods I have tried to optimize softmax / variations of Softmax\n",
        "\n",
        "`drop_lowest_values()`: \n",
        "This function takes the tensor, takes the lowest 10% of output vectors and makes them 0. Using this the default accuracy of softmax increased by ~4-5%\n",
        "\n",
        "`GumbelSoftmax`:\n",
        "Takes in temperature parameter (lamba) and applies noise along with the division term to each term followed by Softmax of that matrix.\n",
        "\n",
        "`LogGumbelSoftmax`:\n",
        "Functions same as GumbelSoftmax, just takes the log of the output matrix.\n",
        "\n",
        "`PseudoSoftmax`:\n",
        "2^z_i instead of e^z_i\n",
        "\n",
        "`ExpSinSoftmax`:\n",
        "As the name suggests, calculates the sin of the output tensor followed by Softmax.\n",
        "\n",
        "`Z_sm`:\n",
        "As the name suggests, calculates the probability (CDF) of that vector as if it were part of a standard normal distribution, followed by Softmax.\n"
      ],
      "metadata": {
        "id": "X80dj9_Cn6uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def drop_lowest_values(tensor):\n",
        "    num_elements = tensor.numel()  # Total number of elements in the tensor\n",
        "    num_values_to_drop = int(num_elements * 0.1)  # Number of values to drop (10% of total)\n",
        "    \n",
        "    if num_values_to_drop == 0:\n",
        "        return tensor\n",
        "    \n",
        "    flattened_tensor = tensor.flatten()  # Flatten the tensor into a 1D tensor\n",
        "    sorted_indices = torch.argsort(flattened_tensor)  # Sort the indices based on the tensor values\n",
        "    \n",
        "    # Set the lowest values to 0\n",
        "    sorted_indices_to_drop = sorted_indices[:num_values_to_drop]\n",
        "    flattened_tensor[sorted_indices_to_drop] = 0\n",
        "    \n",
        "    # Reshape the tensor back to its original shape\n",
        "    dropped_tensor = flattened_tensor.reshape(tensor.shape)\n",
        "    \n",
        "    return dropped_tensor"
      ],
      "metadata": {
        "id": "tIGZKyAmETEe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GumbleSoftmax(nn.Module):\n",
        "    def __init__(self, temperature):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, input):\n",
        "        gumbel_noise = torch.rand_like(input)\n",
        "        gumbel_noise = -torch.log(-torch.log(gumbel_noise + 1e-20) + 1e-20)\n",
        "        logits = (input + gumbel_noise) / self.temperature\n",
        "        return F.softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "c49cI7uLXfta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LogGumbleSoftmax(nn.Module):\n",
        "    def __init__(self, temperature):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def forward(self, input):\n",
        "        gumbel_noise = torch.rand_like(input)\n",
        "        gumbel_noise = -torch.log(-torch.log(gumbel_noise + 1e-20) + 1e-20)\n",
        "        logits = (input + gumbel_noise) / self.temperature\n",
        "        return F.log_softmax(logits, dim=1)"
      ],
      "metadata": {
        "id": "knJJxxkgsjFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PseudoSoftmax(nn.Module):\n",
        "    def forward(self, input):\n",
        "        exp_input = torch.pow(2, input)\n",
        "        softmax_output = exp_input / torch.sum(exp_input, dim=1, keepdim=True)\n",
        "        return softmax_output"
      ],
      "metadata": {
        "id": "KIP1nUUuYDK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Sparsemax activation function.\n",
        "\n",
        "Pytorch implementation of Sparsemax function from:\n",
        "-- \"From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification\"\n",
        "-- André F. T. Martins, Ramón Fernandez Astudillo (http://arxiv.org/abs/1602.02068)\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "class Sparsemax(nn.Module):\n",
        "    \"\"\"Sparsemax function.\"\"\"\n",
        "\n",
        "    def __init__(self, dim=None):\n",
        "        \"\"\"Initialize sparsemax activation\n",
        "        \n",
        "        Args:\n",
        "            dim (int, optional): The dimension over which to apply the sparsemax function.\n",
        "        \"\"\"\n",
        "        super(Sparsemax, self).__init__()\n",
        "\n",
        "        self.dim = -1 if dim is None else dim\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"Forward function.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Input tensor. First dimension should be the batch size\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: [batch_size x number_of_logits] Output tensor\n",
        "\n",
        "        \"\"\"\n",
        "        # Sparsemax currently only handles 2-dim tensors,\n",
        "        # so we reshape to a convenient shape and reshape back after sparsemax\n",
        "        input = input.transpose(0, self.dim)\n",
        "        original_size = input.size()\n",
        "        input = input.reshape(input.size(0), -1)\n",
        "        input = input.transpose(0, 1)\n",
        "        dim = 1\n",
        "\n",
        "        number_of_logits = input.size(dim)\n",
        "\n",
        "        # Translate input by max for numerical stability\n",
        "        input = input - torch.max(input, dim=dim, keepdim=True)[0].expand_as(input)\n",
        "\n",
        "        # Sort input in descending order.\n",
        "        # (NOTE: Can be replaced with linear time selection method described here:\n",
        "        # http://stanford.edu/~jduchi/projects/DuchiShSiCh08.html)\n",
        "        zs = torch.sort(input=input, dim=dim, descending=True)[0]\n",
        "        range = torch.arange(start=1, end=number_of_logits + 1, step=1, device=device, dtype=input.dtype).view(1, -1)\n",
        "        range = range.expand_as(zs)\n",
        "\n",
        "        # Determine sparsity of projection\n",
        "        bound = 1 + range * zs\n",
        "        cumulative_sum_zs = torch.cumsum(zs, dim)\n",
        "        is_gt = torch.gt(bound, cumulative_sum_zs).type(input.type())\n",
        "        k = torch.max(is_gt * range, dim, keepdim=True)[0]\n",
        "\n",
        "        # Compute threshold function\n",
        "        zs_sparse = is_gt * zs\n",
        "\n",
        "        # Compute taus\n",
        "        taus = (torch.sum(zs_sparse, dim, keepdim=True) - 1) / k\n",
        "        taus = taus.expand_as(input)\n",
        "\n",
        "        # Sparsemax\n",
        "        self.output = torch.max(torch.zeros_like(input), input - taus)\n",
        "\n",
        "        # Reshape back to original shape\n",
        "        output = self.output\n",
        "        output = output.transpose(0, 1)\n",
        "        output = output.reshape(original_size)\n",
        "        output = output.transpose(0, self.dim)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        \"\"\"Backward function.\"\"\"\n",
        "        dim = 1\n",
        "\n",
        "        nonzeros = torch.ne(self.output, 0)\n",
        "        sum = torch.sum(grad_output * nonzeros, dim=dim) / torch.sum(nonzeros, dim=dim)\n",
        "        self.grad_input = nonzeros * (grad_output - sum.expand_as(grad_output))\n",
        "\n",
        "        return self.grad_input"
      ],
      "metadata": {
        "id": "RaaH_xccX7vT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExpSinSoftmax(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        exp_sin_values = torch.exp(torch.tanh(input))\n",
        "        probabilities = exp_sin_values / torch.sum(exp_sin_values)\n",
        "        return probabilities\n"
      ],
      "metadata": {
        "id": "UMfznFfaYBoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Z_sm(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "    def forward(self,input):\n",
        "        \n",
        "        device = input.device\n",
        "        m = torch.distributions.normal.Normal(torch.tensor([0.0], device=device), torch.tensor([1.0], device=device))\n",
        "        log_probs = m.icdf(input)\n",
        "        probabilities = torch.exp(log_probs) / torch.sum(torch.exp(log_probs))\n",
        "        return probabilities\n"
      ],
      "metadata": {
        "id": "winp9QsNmiSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resnet 12 Image classifier architecture as per the paper: https://www.researchgate.net/publication/329954455_Short-Term_Load_Forecasting_based_on_ResNet_and_LSTM\n"
      ],
      "metadata": {
        "id": "YMRcG6zdtU2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Resnet12 Layer Structure\n",
        "\n",
        "def conv_block(in_channels, out_channels, pool=False):\n",
        "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1), \n",
        "              nn.BatchNorm2d(out_channels), \n",
        "              nn.ReLU(inplace=True)]\n",
        "    if pool: layers.append(nn.MaxPool2d(2))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class ResNet12(ImageClassificationBase):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = conv_block(in_channels, 64)\n",
        "        self.conv2 = conv_block(64, 128, pool=True)\n",
        "        self.res1 = nn.Sequential(conv_block(128, 128), conv_block(128, 128))\n",
        "        \n",
        "        self.conv3 = conv_block(128, 256, pool=True)\n",
        "        self.conv4 = conv_block(256, 512, pool=True)\n",
        "        self.res2 = nn.Sequential(conv_block(512, 512), conv_block(512, 512))\n",
        "        \n",
        "        self.conv5 = conv_block(512, 1024, pool=True)\n",
        "        self.res3 = nn.Sequential(conv_block(1024, 1024), conv_block(1024, 1024))\n",
        "        \n",
        "        self.classifier = nn.Sequential(nn.MaxPool2d(2), \n",
        "                                        nn.Flatten(), \n",
        "                                        nn.Linear(1024, num_classes),\n",
        "                                        # LogGumbleSoftmax(temperature = 3),\n",
        "                                        # PseudoSoftmax(),\n",
        "                                        # Z_sm(),\n",
        "                                        )\n",
        "        \n",
        "\n",
        "        self.softmax_layer = nn.LogSoftmax(dim = 1)\n",
        "        # self.softmax_layer = nn.Softmax(dim = 1)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.conv1(xb)\n",
        "        out = self.conv2(out)\n",
        "        out = self.res1(out) + out\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.res2(out) + out\n",
        "        out = self.conv5(out)\n",
        "        out = self.res3(out) + out\n",
        "        out = self.classifier(out)\n",
        "\n",
        "        \n",
        "        # out = drop_lowest_values(out)\n",
        "\n",
        "        out = self.softmax_layer(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "BavB8tllrEF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        " # for evaluation thingie"
      ],
      "metadata": {
        "id": "q1MLjOzNJEsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# functions for evaluating the model as it trains\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, val_loader):\n",
        "    model.eval()\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "def fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n",
        "                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n",
        "    torch.cuda.empty_cache()\n",
        "    history = []\n",
        "    \n",
        "    # Set up custom optimizer with weight decay\n",
        "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
        "    # Set up one-cycle learning rate scheduler\n",
        "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n",
        "                                                steps_per_epoch=len(train_loader))\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        model.train()\n",
        "        train_losses = []\n",
        "        lrs = []\n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            train_losses.append(loss)\n",
        "            loss.backward()\n",
        "            \n",
        "            # Gradient clipping\n",
        "            if grad_clip: \n",
        "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
        "            \n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Record & update learning rate\n",
        "            lrs.append(get_lr(optimizer))\n",
        "            sched.step()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
        "        result['lrs'] = lrs\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    \n",
        "     # After completing training, evaluate on the validation set\n",
        "    model.eval()\n",
        "    predicted_labels = []\n",
        "    true_labels = []\n",
        "    for batch in val_loader:\n",
        "        outputs = model(batch[0])\n",
        "        predicted_labels.extend(torch.argmax(outputs, dim=1).tolist())\n",
        "        true_labels.extend(batch[1].tolist())\n",
        "\n",
        "    precision = precision_score(true_labels, predicted_labels, average='macro')\n",
        "    recall = recall_score(true_labels, predicted_labels, average='macro')\n",
        "    f1 = f1_score(true_labels, predicted_labels, average='macro')\n",
        "    cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "    history[-1]['precision'] = precision\n",
        "    history[-1]['recall'] = recall\n",
        "    history[-1]['f1'] = f1\n",
        "    history[-1]['confusion_matrix'] = cm\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "bXwpdpFzmn--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_resnet12 = to_device(ResNet12(3, 100), device)\n",
        "model_resnet12"
      ],
      "metadata": {
        "id": "TfXpg6xsrSgC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f19042b-a567-4271-91a9-f59424b34fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet12(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res1): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv3): Sequential(\n",
              "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv4): Sequential(\n",
              "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res2): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (conv5): Sequential(\n",
              "    (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (res3): Sequential(\n",
              "    (0): Sequential(\n",
              "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Sequential(\n",
              "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Flatten(start_dim=1, end_dim=-1)\n",
              "    (2): Linear(in_features=1024, out_features=100, bias=True)\n",
              "    (3): PseudoSoftmax()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model_resnet12, (3,32,32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMtbDUl_s2zq",
        "outputId": "c95e6309-a840-4ba5-b371-d73b73e67712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4          [-1, 128, 32, 32]          73,856\n",
            "       BatchNorm2d-5          [-1, 128, 32, 32]             256\n",
            "              ReLU-6          [-1, 128, 32, 32]               0\n",
            "         MaxPool2d-7          [-1, 128, 16, 16]               0\n",
            "            Conv2d-8          [-1, 128, 16, 16]         147,584\n",
            "       BatchNorm2d-9          [-1, 128, 16, 16]             256\n",
            "             ReLU-10          [-1, 128, 16, 16]               0\n",
            "           Conv2d-11          [-1, 128, 16, 16]         147,584\n",
            "      BatchNorm2d-12          [-1, 128, 16, 16]             256\n",
            "             ReLU-13          [-1, 128, 16, 16]               0\n",
            "           Conv2d-14          [-1, 256, 16, 16]         295,168\n",
            "      BatchNorm2d-15          [-1, 256, 16, 16]             512\n",
            "             ReLU-16          [-1, 256, 16, 16]               0\n",
            "        MaxPool2d-17            [-1, 256, 8, 8]               0\n",
            "           Conv2d-18            [-1, 512, 8, 8]       1,180,160\n",
            "      BatchNorm2d-19            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-20            [-1, 512, 8, 8]               0\n",
            "        MaxPool2d-21            [-1, 512, 4, 4]               0\n",
            "           Conv2d-22            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-23            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-24            [-1, 512, 4, 4]               0\n",
            "           Conv2d-25            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-26            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-27            [-1, 512, 4, 4]               0\n",
            "           Conv2d-28           [-1, 1024, 4, 4]       4,719,616\n",
            "      BatchNorm2d-29           [-1, 1024, 4, 4]           2,048\n",
            "             ReLU-30           [-1, 1024, 4, 4]               0\n",
            "        MaxPool2d-31           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-32           [-1, 1024, 2, 2]       9,438,208\n",
            "      BatchNorm2d-33           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-34           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-35           [-1, 1024, 2, 2]       9,438,208\n",
            "      BatchNorm2d-36           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-37           [-1, 1024, 2, 2]               0\n",
            "        MaxPool2d-38           [-1, 1024, 1, 1]               0\n",
            "          Flatten-39                 [-1, 1024]               0\n",
            "           Linear-40                  [-1, 100]         102,500\n",
            "    PseudoSoftmax-41                  [-1, 100]               0\n",
            "================================================================\n",
            "Total params: 30,274,916\n",
            "Trainable params: 30,274,916\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 9.67\n",
            "Params size (MB): 115.49\n",
            "Estimated Total Size (MB): 125.17\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_resnet12 = [evaluate(model_resnet12, val_loader)]\n",
        "history_resnet12"
      ],
      "metadata": {
        "id": "sjPN5_3brUFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting parameters for training**"
      ],
      "metadata": {
        "id": "Q8lYrWoGms1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs_resnet12 = 50\n",
        "max_lr = 0.01\n",
        "grad_clip = 0.1\n",
        "weight_decay = 1e-5\n",
        "opt_func = torch.optim.Adam ##optimizer funcction"
      ],
      "metadata": {
        "id": "J3jqtMb9rfMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "## trains the model, while recording needed statistics\n",
        "history_resnet12 += fit_one_cycle(epochs_resnet12, max_lr, model_resnet12, train_loader, val_loader, \n",
        "                             grad_clip=grad_clip, \n",
        "                             weight_decay=weight_decay, \n",
        "                             opt_func=opt_func)\n"
      ],
      "metadata": {
        "id": "A3Dj166LrgJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model"
      ],
      "metadata": {
        "id": "P8tvebVsmz8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(cm, class_names):\n",
        "    plt.figure(figsize=(50, 50))\n",
        "    # plt.imshow(cm, interpolation='nearest', cmap=plt.cm.OrRd)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=plt.colormaps['magma'])\n",
        "\n",
        "    ## https://matplotlib.org/stable/tutorials/colors/colormaps.html#lightness-of-matplotlib-colormaps\n",
        "\n",
        "    plt.colorbar(shrink=0.50)\n",
        "    \n",
        "    tick_marks = np.arange(len(class_names))\n",
        "    plt.xticks(tick_marks, class_names, rotation=45)\n",
        "    plt.yticks(tick_marks, class_names)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "last_result = history_resnet12[-1]\n",
        "cm = last_result['confusion_matrix']\n",
        "plot_confusion_matrix(cm, classes)"
      ],
      "metadata": {
        "id": "abTUJkvHJRCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_result = history_resnet12[-1]\n",
        "precision = last_result['precision']\n",
        "recall = last_result['recall']\n",
        "f1 = last_result['f1']\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "id": "9f2VlVBbOFBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-o', color = 'black')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy vs. Number of Epochs');"
      ],
      "metadata": {
        "id": "7XmZPAM8nAED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_accuracies(history_resnet12)"
      ],
      "metadata": {
        "id": "Hj4rtYz_m1lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_losses(history):\n",
        "    train_losses = [x.get('train_loss') for x in history]\n",
        "    val_losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(train_losses, color = 'green')\n",
        "    plt.plot(val_losses, color = 'brown')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(['Training', 'Validation'])\n",
        "    plt.title('Loss vs. Number of epochs');"
      ],
      "metadata": {
        "id": "tQFF_RpQm25J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_losses(history_resnet12)"
      ],
      "metadata": {
        "id": "BOCYarB-m4Id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_lrs(history):\n",
        "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
        "    plt.plot(lrs, color = 'orange')\n",
        "    plt.xlabel('Batch Number')\n",
        "    plt.ylabel('Learning Rate')\n",
        "    plt.title('Learning Rate vs. Batch Number');"
      ],
      "metadata": {
        "id": "JgggncVsm5L6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_lrs(history_resnet12)"
      ],
      "metadata": {
        "id": "K-bbz2d1m6LG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_resnet12 = evaluate(model_resnet12, test_loader) \n",
        "\n",
        "#final evaluation of resnet12 model with test dataset\n",
        "\n",
        "test_resnet12"
      ],
      "metadata": {
        "id": "kx2aJmt9nFy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_resnet12 = test_resnet12['val_loss']\n",
        "test_acc_resnet12 = test_resnet12['val_acc']\n",
        "print('test_loss_resnet9:', test_resnet12['val_loss'])\n",
        "print('test_acc_resnet9:', test_resnet12['val_acc'])"
      ],
      "metadata": {
        "id": "aSW5bNs6nHBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model_resnet12.state_dict(), 'ResNet12_v1_log_softmax.pth')\n",
        "\n",
        "#saves the trained model weights"
      ],
      "metadata": {
        "id": "hg8cFksonIqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_image(img, model_resnet12):\n",
        "    # Convert to a batch of 1\n",
        "    xb = to_device(img.unsqueeze(0), device)\n",
        "    # Get predictions from model\n",
        "    yb = model_resnet12(xb)\n",
        "    # Pick index with highest probability\n",
        "    _, preds  = torch.max(yb, dim=1)\n",
        "\n",
        "    print(yb)\n",
        "    \n",
        "    # Retrieve the class label\n",
        "    # return yb\n",
        "\n",
        "    return dataset.classes[preds[0].item()]"
      ],
      "metadata": {
        "id": "kwx-QAPwnMxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M3AMcZ64DcgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = test_dataset[3480]\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "print('Label:', dataset.classes[label], ', Predicted:', predict_image(img, model_resnet12))"
      ],
      "metadata": {
        "id": "jzTdBCapnNwk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}